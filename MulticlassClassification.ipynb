{
 "metadata": {
  "name": "",
  "signature": "sha256:44c52ee1b174d9f2e7870c63f450ecaf9de9a14c681e5dde35cc803b4dbf85e9"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Multiclass Classification\n",
      "\n",
      "As convenient as it would be, most things in the world are not binary prediction problems. Many are multiclass prediction problems: given an input, map it to one of 10 classes, or 20 classes, or 100k classes.\n",
      "\n",
      "# 20 Newsgroups\n",
      "\n",
      "As a running example, we'll use the 20 Newsgroups dataset. This contains about 20,000 postings to 20 different newsgroups on usenet; the classification task is to put a posting into the proper newsgroup. The set of newsgroups are:\n",
      "\n",
      "    comp.graphics       comp.os.ms-windows.misc  comp.sys.ibm.pc.hardware  comp.sys.mac.hardware  comp.windows.x\n",
      "    talk.politics.misc  talk.politics.guns       talk.politics.mideast     talk.religion.misc\n",
      "    rec.autos           rec.motorcycles          rec.sport.baseball        rec.sport.hockey\n",
      "    sci.crypt           sci.electronics          sci.med                   sci.space\n",
      "    alt.atheism         soc.religion.christian\n",
      "    misc.forsale\n",
      "\n",
      "which we first need to download and extract. Thankfully, [Jason Rennie has a nice distribution](http://qwone.com/~jason/20Newsgroups/); this is a 14mb download."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!rm -rf data/20news-*\n",
      "!curl -o data/20news-bydate.tar.gz http://qwone.com/~jason/20Newsgroups/20news-bydate.tar.gz\n",
      "!tar zxC data -f data/20news-bydate.tar.gz\n",
      "!echo \"\"\n",
      "!echo \"List of directories:\"\n",
      "!echo \"\"\n",
      "!ls data/20news-bydate-train/\n",
      "!echo \"\"\n",
      "!echo \"First training document in comp.windows.x\"\n",
      "!echo \"\"\n",
      "!head -n40 data/20news-bydate-train/comp.windows.x/64830"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\r\n",
        "                                 Dload  Upload   Total   Spent    Left  Speed\r\n",
        "\r",
        "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "  0 13.7M    0 43195    0     0   181k      0  0:01:17 --:--:--  0:01:17  181k"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "  6 13.7M    6  959k    0     0   782k      0  0:00:18  0:00:01  0:00:17  781k"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        " 27 13.7M   27 3860k    0     0  1732k      0  0:00:08  0:00:02  0:00:06 1732k"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        " 50 13.7M   50 7146k    0     0  2213k      0  0:00:06  0:00:03  0:00:03 2213k"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        " 73 13.7M   73 10.1M    0     0  2468k      0  0:00:05  0:00:04  0:00:01 2467k"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        " 97 13.7M   97 13.4M    0     0  2624k      0  0:00:05  0:00:05 --:--:-- 2737k"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "100 13.7M  100 13.7M    0     0  2639k      0  0:00:05  0:00:05 --:--:-- 3193k\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "List of directories:\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "alt.atheism\t\t  comp.sys.mac.hardware  rec.motorcycles     sci.electronics\t     talk.politics.guns\r\n",
        "comp.graphics\t\t  comp.windows.x\t rec.sport.baseball  sci.med\t\t     talk.politics.mideast\r\n",
        "comp.os.ms-windows.misc   misc.forsale\t\t rec.sport.hockey    sci.space\t\t     talk.politics.misc\r\n",
        "comp.sys.ibm.pc.hardware  rec.autos\t\t sci.crypt\t     soc.religion.christian  talk.religion.misc\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "First training document in comp.windows.x\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "From: chongo@toad.com (Landon C. Noll)\r\n",
        "Subject: 10th International Obfuscated C Code Contest Opening (1 of 2)\r\n",
        "Keywords: ioccc\r\n",
        "Article-I.D.: toad.32194\r\n",
        "Expires: 7 May 93 00:00:00 GMT\r\n",
        "Reply-To: chongo@toad.com.UUCP (Landon C. Noll)\r\n",
        "Distribution: world\r\n",
        "Organization: Nebula Consultants in San Francisco\r\n",
        "Lines: 850\r\n",
        "\r\n",
        "Enclosed are the rules, guidelines and related information for the 10th\r\n",
        "International Obfuscated C Code Contest.  (This is part 1 of a 2 part\r\n",
        "shar file).\r\n",
        "\r\n",
        "Enjoy!\r\n",
        "\r\n",
        "chongo <Landon Curt Noll> /\\oo/\\ \r\n",
        "Larry Bassel\r\n",
        "\r\n",
        "=-=\r\n",
        "\r\n",
        "#!/bin/sh\r\n",
        "# This is a shell archive (shar 3.32)\r\n",
        "# made 03/01/1993 12:01 UTC by chongo@toad.com\r\n",
        "# Source directory /tmp\r\n",
        "#\r\n",
        "# existing files WILL be overwritten\r\n",
        "#\r\n",
        "# This shar contains:\r\n",
        "# length  mode       name\r\n",
        "# ------ ---------- ------------------------------------------\r\n",
        "#   8585 -r--r--r-- rules\r\n",
        "#  25375 -r--r--r-- guidelines\r\n",
        "#  33961 -r--r--r-- mkentry.c\r\n",
        "#   6257 -r--r--r-- obfuscate.info\r\n",
        "#\r\n",
        "# ============= rules ==============\r\n",
        "echo \"x - extracting rules (Text)\"\r\n",
        "sed 's/^X//' << 'SHAR_EOF' > rules &&\r\n",
        "X10th International Obfuscated C Code Contest Rules\r\n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "As you're probably used to, our first step is to get this into `vw` format.\n",
      "\n",
      "Although `vw` does support labels with names, we're going to map the labels to numbers. We'll come back to named labels later.\n",
      "\n",
      "For features, we'll extract the different email headers to different namespaces, and then the body of the message to a separate namespace. We'll do very stupid tokenization; I'm sure you could do better if you wanted.\n",
      "\n",
      "Here's some code to generate the relevant `vw` files:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import re, os\n",
      "\n",
      "def sanify(s): return s.replace(':',';').replace('|','/')   # replace : with ; and | with /\n",
      "def tokenize(s): return re.sub('([^A-Za-z0-9 ]+)', ' \\\\1 ', s).split()  # add space around anything not alphanum\n",
      "\n",
      "headerToNamespace = {'Subject': 'S',\n",
      "                     'From': 'F',\n",
      "                     'Organization': 'O',\n",
      "                     'Distribution': 'D',\n",
      "                     'Reply-To': 'R',\n",
      "                     'Keywords': 'K',\n",
      "                     'Summary': 'U' }\n",
      "\n",
      "def readSinglePost(filename):\n",
      "    with open(filename, 'r') as h:\n",
      "        namespaces = {}\n",
      "        text = []\n",
      "        inText = False\n",
      "        for l in h.readlines():\n",
      "            words = tokenize(l.strip())\n",
      "            if not inText and len(words) == 0:\n",
      "                inText = True\n",
      "            elif inText:\n",
      "                text += words\n",
      "            elif len(words) > 2 and words[1] == ':' and words[0] in headerToNamespace:\n",
      "                ns = headerToNamespace[words[0]]\n",
      "                namespaces[ns] = words[2:]\n",
      "        namespaces['w'] = text\n",
      "        return namespaces\n",
      "\n",
      "def postToVW(label, namespaces):\n",
      "    ex = str(label)\n",
      "    for ns,words in namespaces.iteritems():\n",
      "        ex += ' |%s %s' % (ns, ' '.join(map(sanify,words[:5000])))  # only take the first 5k words of a post\n",
      "    return ex\n",
      "\n",
      "def readPostsInDirectory(directory):\n",
      "    return [readSinglePost(directory + os.sep + f)\n",
      "            for f in os.listdir(directory)\n",
      "            if  f.isdigit()]   # all file names are just numbers\n",
      "\n",
      "def readAllPosts(baseDirectory, newsgroups):\n",
      "    examples = []\n",
      "    for name,label in newsgroups.iteritems():\n",
      "        posts = readPostsInDirectory(baseDirectory + os.sep + name)\n",
      "        examples += [postToVW(label, post) for post in posts]\n",
      "    return examples\n",
      "\n",
      "def writeFile(filename, examples):\n",
      "    with open(filename,'w') as h:\n",
      "        for ex in examples:\n",
      "            print >>h, ex\n",
      "\n",
      "newsgroupNames = 'comp.graphics comp.os.ms-windows.misc comp.sys.ibm.pc.hardware comp.sys.mac.hardware comp.windows.x talk.politics.misc talk.politics.guns talk.politics.mideast talk.religion.misc rec.autos rec.motorcycles rec.sport.baseball rec.sport.hockey sci.crypt sci.electronics sci.med sci.space alt.atheism soc.religion.christian misc.forsale'.split()\n",
      "newsgroups = { name: k+1 for k,name in enumerate(newsgroupNames) }   # label ids have to start at 1, not 0\n",
      "\n",
      "train = readAllPosts('data/20news-bydate-train', newsgroups)\n",
      "test  = readAllPosts('data/20news-bydate-test',  newsgroups)\n",
      "\n",
      "import random\n",
      "random.seed(9876)\n",
      "random.shuffle(train)\n",
      "\n",
      "print 'read %d training examples and %d test examples' % (len(train), len(test))\n",
      "\n",
      "writeFile('data/20ng.tr', train)\n",
      "writeFile('data/20ng.te', test)\n",
      "\n",
      "print 'files generated:'\n",
      "!wc data/20ng.tr data/20ng.te"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "read 11314 training examples and 7532 test examples\n",
        "files generated:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "   11314  4248707 19864878 data/20ng.tr\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "    7532  2731355 12832796 data/20ng.te\r\n",
        "   18846  6980062 32697674 total\r\n"
       ]
      }
     ],
     "prompt_number": 21
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# <a id=\"train\"></a> Training VW using One Against All\n",
      "\n",
      "We now have to train `vw`. Basically the only difference between a multiclass run of `vw` and a binary classification run is that you have to tell `vw` how you want it to solve the multiclass problem, and how many classes there are.\n",
      "\n",
      "A very reasonable method for multiclass classification is **One Against All** (OAA), which, on $K$ classes, trains $K$ regressors, each to predict a particular class. We can do this for 20 Newsgroups by simply saying \"`--oaa 20`\" on the command line."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!vw -k -c -b 27 --oaa 20 -d data/20ng.tr -f data/20ng.model --passes 20 --holdout_after 10001"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "final_regressor = data/20ng.model\r\n",
        "Num weight bits = 27\r\n",
        "learning rate = 0.5\r\n",
        "initial_t = 0\r\n",
        "power_t = 0.5\r\n",
        "decay_learning_rate = 1\r\n",
        "creating cache_file = data/20ng.tr.cache\r\n",
        "Reading datafile = data/20ng.tr\r\n",
        "num sources = 1\r\n",
        "average  since         example        example  current  current  current\r\n",
        "loss     last          counter         weight    label  predict features\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "1.000000 1.000000            1            1.0       16        1      485\r\n",
        "0.500000 0.000000            2            2.0       16       16      189\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.750000 1.000000            4            4.0        4        1      397\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.875000 1.000000            8            8.0        8       17      556\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.875000 0.875000           16           16.0        4       10       65\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.906250 0.937500           32           32.0       10       19      360\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.859375 0.812500           64           64.0        8        8     1854\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.875000 0.890625          128          128.0        3        7      183\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.828125 0.781250          256          256.0       14        6      108\r\n",
        "0.748047 0.667969          512          512.0       20       20       52\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.625977 0.503906         1024         1024.0        1        1       75\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.490234 0.354492         2048         2048.0        6        9      357\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.358643 0.227051         4096         4096.0       14       14     1373\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.255859 0.153076         8192         8192.0       16       16      378\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.116438 0.116438        16384        16384.0       17       17       93 h\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.103501 0.097032        32768        32768.0       19       19      725 h\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.096905 0.090309        65536        65536.0       19       19      203 h\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r\n",
        "finished run\r\n",
        "number of examples per pass = 10000\r\n",
        "passes used = 8\r\n",
        "weighted example sum = 80000.000000\r\n",
        "weighted label sum = 0.000000\r\n",
        "average loss = 0.088280 h\r\n",
        "total feature number = 29528008\r\n"
       ]
      }
     ],
     "prompt_number": 22
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "At the end, we have a holdout loss of about 9.0% -- this is just the fraction of errors we make. This is pretty reasonable; [Jason Rennie reports 15% error](http://people.csail.mit.edu/jrennie/writing/loocv.pdf) also on the test data. But we expect test performance should be similar to heldout performance. Let's make sure:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!vw -t -i data/20ng.model -d data/20ng.te"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "only testing\r\n",
        "Num weight bits = 27\r\n",
        "learning rate = 0.5\r\n",
        "initial_t = 0\r\n",
        "power_t = 0.5\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "using no cache\r\n",
        "Reading datafile = data/20ng.te\r\n",
        "num sources = 1\r\n",
        "average  since         example        example  current  current  current\r\n",
        "loss     last          counter         weight    label  predict features\r\n",
        "0.000000 0.000000            1            1.0       20       20       28\r\n",
        "0.000000 0.000000            2            2.0       20       20      903\r\n",
        "0.000000 0.000000            4            4.0       20       20      173\r\n",
        "0.000000 0.000000            8            8.0       20       20      135\r\n",
        "0.000000 0.000000           16           16.0       20       20      107\r\n",
        "0.000000 0.000000           32           32.0       20       20       85\r\n",
        "0.125000 0.250000           64           64.0       20       13     1546\r\n",
        "0.117188 0.109375          128          128.0       20       20       26\r\n",
        "0.113281 0.109375          256          256.0       20       20      203\r\n",
        "0.109375 0.105469          512          512.0        7        7      419\r\n",
        "0.154297 0.199219         1024         1024.0        4        4      277\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.200684 0.247070         2048         2048.0        1        1      161\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.220703 0.240723         4096         4096.0        2        2      184\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r\n",
        "finished run\r\n",
        "number of examples per pass = 7532\r\n",
        "passes used = 1\r\n",
        "weighted example sum = 7532.000000\r\n",
        "weighted label sum = 0.000000\r\n",
        "average loss = 0.193043\r\n",
        "total feature number = 2699311\r\n"
       ]
      }
     ],
     "prompt_number": 23
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Okay, so 19% error is actually much worse than 9% error. This suggests the training and test distributions don't match up entirely. Oh well. Still ballpark reasonable for putting no effort into it.\n",
      "\n",
      "A few notes:\n",
      "\n",
      "* When I trained the model, I used a slightly larger number of bits than before. This is because in OAA, we're storing 20 different weight vectors in the same amount of space. If you want each weight vector to have the, say, 24 bits of representation, then you should run with 28 or 29 total bits to account for the fact that you need to pack in 20 different vectors.\n",
      "\n",
      "* When I tested the model I didn't need to say `--oaa` again; this is stored in the saved model and therefore unnecessary.\n",
      "\n",
      "# <a id=\"human\"></a> Getting a Human Readable Model\n",
      "\n",
      "The mechanism for getting a human-readable model out is basically the same as always. We train a model, then rerun with `--invert_hash -t` over the training data."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!vw -t -i data/20ng.model -d data/20ng.tr --invert_hash data/20ng.model.readable"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "only testing\r\n",
        "Num weight bits = 27\r\n",
        "learning rate = 0.5\r\n",
        "initial_t = 0\r\n",
        "power_t = 0.5\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "using no cache\r\n",
        "Reading datafile = data/20ng.tr\r\n",
        "num sources = 1\r\n",
        "average  since         example        example  current  current  current\r\n",
        "loss     last          counter         weight    label  predict features\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.000000 0.000000            1            1.0       16       16      485\r\n",
        "0.000000 0.000000            2            2.0       16       16      189\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.000000 0.000000            4            4.0        4        4      397\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.000000 0.000000            8            8.0        8        8      556\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.000000 0.000000           16           16.0        4        4       65\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.000000 0.000000           32           32.0       10       10      360\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.000000 0.000000           64           64.0        8        8     1854\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.000000 0.000000          128          128.0        3        3      183\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.000000 0.000000          256          256.0       14       14      108\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.000000 0.000000          512          512.0       20       20       52\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.000000 0.000000         1024         1024.0        1        1       75\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.000488 0.000977         2048         2048.0        6        6      357\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.000977 0.001465         4096         4096.0       14       14     1373\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.000732 0.000488         8192         8192.0       16       16      378\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r\n",
        "finished run\r\n",
        "number of examples per pass = 11314\r\n",
        "passes used = 1\r\n",
        "weighted example sum = 11314.000000\r\n",
        "weighted label sum = 0.000000\r\n",
        "average loss = 0.010783\r\n",
        "total feature number = 4200183\r\n"
       ]
      }
     ],
     "prompt_number": 24
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Unfortunately, this is quite slow and memory-hogging on my laptop (about 1gb ram, a few minutes). On the bright side, this *does* demonstrate that there's a big win for now dealing with strings during normal training!\n",
      "\n",
      "Once that's done, we can look at specific features. For instance, we might be interested in the feature \"DoD\" (probably \"Department of Defense\") in the \"w\" (words) namespace:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!grep '^w^bike\\[' data/20ng.model.readable"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "w^bike[10]:2726282:0.267182\r\n",
        "w^bike[11]:2726283:-0.0654002\r\n",
        "w^bike[12]:2726284:-0.0674678\r\n",
        "w^bike[13]:2726285:-0.0664337\r\n",
        "w^bike[14]:2726286:-0.0929826\r\n",
        "w^bike[15]:2726287:-0.0948727\r\n",
        "w^bike[16]:2726288:-0.0729316\r\n",
        "w^bike[17]:2726289:-0.0585717\r\n",
        "w^bike[18]:2726290:-0.0612998\r\n",
        "w^bike[19]:2726291:-0.0885388\r\n",
        "w^bike[1]:2726273:-0.0527149\r\n",
        "w^bike[2]:2726274:-0.0998297\r\n",
        "w^bike[3]:2726275:-0.0917529\r\n",
        "w^bike[4]:2726276:-0.088493\r\n",
        "w^bike[5]:2726277:-0.0439067\r\n",
        "w^bike[6]:2726278:-0.0628997\r\n",
        "w^bike[7]:2726279:-0.0367412\r\n",
        "w^bike[8]:2726280:-0.0519108\r\n",
        "w^bike[9]:2726281:-0.203572\r\n"
       ]
      }
     ],
     "prompt_number": 25
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The way to read this is as follows. For the `w` namespace, there's a feature `bike`. It has a separate weight for each of the classes `0..19` (this is potentially an annoying source of off-by-one erorrs since in the input file we have classes `1..20`... sigh, sorry!).\n",
      "\n",
      "The class that `bike` is most indicative of is vw label `[10]` (with a weight of 0.267542). This is our class 11. Which class is that?"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print newsgroups"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "{'misc.forsale': 20, 'talk.politics.guns': 7, 'comp.sys.mac.hardware': 4, 'talk.politics.misc': 6, 'soc.religion.christian': 19, 'comp.graphics': 1, 'sci.med': 16, 'talk.religion.misc': 9, 'comp.windows.x': 5, 'comp.sys.ibm.pc.hardware': 3, 'talk.politics.mideast': 8, 'comp.os.ms-windows.misc': 2, 'sci.crypt': 14, 'sci.space': 17, 'alt.atheism': 18, 'rec.sport.hockey': 13, 'rec.sport.baseball': 12, 'sci.electronics': 15, 'rec.autos': 10, 'rec.motorcycles': 11}\n"
       ]
      }
     ],
     "prompt_number": 26
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Okay, so it's `rec.motorcycles`. This passes the sanity check!\n",
      "\n",
      "We can also just look at the top weighted features:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!cat data/20ng.model.readable | tail -n+14 | sort -t: -k3g | tail"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "O^Internet[4]:68061476:0.197918\r\n",
        "w^Mac[3]:130059683:0.200883\r\n",
        "w^Motif[4]:35326788:0.201141\r\n",
        "w^Apple[3]:68185219:0.220605\r\n",
        "w^car[9]:131766281:0.237401\r\n",
        "S^Windows[1]:11423937:0.246461\r\n",
        "w^DoD[10]:112357258:0.25532\r\n",
        "w^Windows[1]:24350241:0.261268\r\n",
        "w^bike[10]:2726282:0.267182\r\n",
        "w^RAHE[10]:2726282:0.267182\r\n"
       ]
      }
     ],
     "prompt_number": 27
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The top two are the `w`ord namespace, but the third one (`S^Windows`) is the Subject line namespace. In this case it's indicative of label `[1]` which is class 2, which, looking above, is `comp.os-ms-windows.misc`.\n",
      "\n",
      "# <a id=\"raw\"> Getting (Raw) Predictions\n",
      "\n",
      "As before, often we want to get label predictions (which class?) and/or per-label scores (a ranking?). We can get the class predictions with `-p` and the score with `-r`. Let's do this for the test data."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!vw -t -i data/20ng.model -d data/20ng.te -p data/20ng.te.pred -r data/20ng.te.raw --quiet\n",
      "!head data/20ng.te.pred data/20ng.te.raw"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "==> data/20ng.te.pred <==\r\n",
        "20\r\n",
        "20\r\n",
        "20\r\n",
        "20\r\n",
        "20\r\n",
        "20\r\n",
        "20\r\n",
        "20\r\n",
        "20\r\n",
        "20\r\n",
        "\r\n",
        "==> data/20ng.te.raw <==\r\n",
        "1:-0.853361 2:-0.579047 3:-0.496283 4:-0.687331 5:-0.432544 6:-0.785103 7:-0.545463 8:-0.786593 9:-0.680298 10:-0.416863 11:-0.631276 12:-0.576203 13:-0.648957 14:-0.663446 15:-0.659258 16:-0.67069 17:-0.662414 18:-0.842984 19:-0.769787 20:0.165929\r\n",
        "1:-1 2:-1 3:-1 4:-1 5:-1 6:-1 7:-1 8:-1 9:-1 10:-1 11:-1 12:-1 13:-1 14:-1 15:-1 16:-1 17:-1 18:-1 19:-1 20:1\r\n",
        "1:-1 2:-1 3:-0.954712 4:-1 5:-1 6:-1 7:-1 8:-1 9:-1 10:-1 11:-1 12:-1 13:-1 14:-1 15:-1 16:-1 17:-1 18:-1 19:-1 20:1\r\n",
        "1:-1 2:-1 3:-1 4:-1 5:-1 6:-1 7:-1 8:-1 9:-1 10:-0.724976 11:-0.957459 12:-1 13:-1 14:-0.823315 15:-1 16:-1 17:-1 18:-1 19:-1 20:0.852422\r\n",
        "1:-0.0449042 2:-1 3:-1 4:-1 5:-1 6:-1 7:-1 8:-1 9:-1 10:-1 11:-0.914778 12:-0.932156 13:-1 14:-1 15:-1 16:-0.999701 17:-0.836377 18:-1 19:-1 20:0.0326969\r\n",
        "1:-1 2:-1 3:-1 4:-0.423718 5:-1 6:-0.835327 7:-1 8:-0.99173 9:-1 10:-0.864126 11:-1 12:-1 13:-1 14:-1 15:-1 16:-0.947122 17:-1 18:-1 19:-0.797685 20:1\r\n",
        "1:-1 2:-0.606142 3:-1 4:-0.801637 5:-1 6:-1 7:-0.806872 8:-1 9:-1 10:-1 11:-0.670458 12:-1 13:-1 14:-1 15:-0.985724 16:-1 17:-1 18:-1 19:-1 20:0.0694964\r\n",
        "1:-1 2:-1 3:-1 4:-1 5:-1 6:-1 7:-1 8:-1 9:-1 10:-1 11:-1 12:-1 13:-1 14:-1 15:-1 16:-1 17:-1 18:-1 19:-1 20:1\r\n",
        "1:-0.535936 2:-1 3:-1 4:-0.826314 5:-0.885376 6:-0.601296 7:-1 8:-0.959748 9:-1 10:-1 11:-1 12:-1 13:-0.856908 14:-1 15:-0.552815 16:-0.914174 17:-1 18:-1 19:-1 20:-0.0436729\r\n",
        "1:-1 2:-1 3:-1 4:-1 5:-1 6:-0.93079 7:-1 8:-1 9:-1 10:-1 11:-1 12:-1 13:-1 14:-1 15:-1 16:-1 17:-1 18:-1 19:-1 20:1\r\n"
       ]
      }
     ],
     "prompt_number": 28
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "In the `.pred` file, we can see the actual predictions (20, 20, 20, ..., 3, 20, 20, ...). These are just the predicted labels.\n",
      "\n",
      "In the `.raw` file, we can see per-class scores. This is still one-line-per-example. For the first line, we can see that every class 1..19 has a negative score and 20 has a positive score. Thus 20 \"wins\" and is the prediction.\n",
      "\n",
      "# <a id=\"namd\"></a> Using Named Classes\n",
      "\n",
      "Sometimes it is inconvenient to have to map class ids to numbers. Using \"named classes\" we can avoid this. The downside is that the class names have to, instead, be specified on the command line.\n",
      "\n",
      "<font size=\"-2\">[Note: you might wonder why `vw` can't just read in named classes as it reads the file and do it's own internal counting of numbers. This is because sometimes you want to run multiple instances of `vw` in parallel. When these instances communicate, they need to agree on the numbering scheme.]</font>\n",
      "\n",
      "To use named classes, you simply: (1) replace the label numbers in the input file(s) with strings; and (2) specify the names on the command line. Here's an example for 20 Newsgroups."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "namedNewsgroups = { name:name for name in newsgroupNames }\n",
      "\n",
      "train = readAllPosts('data/20news-bydate-train', namedNewsgroups)\n",
      "test  = readAllPosts('data/20news-bydate-test',  namedNewsgroups)\n",
      "\n",
      "random.seed(9876)\n",
      "random.shuffle(train)\n",
      "\n",
      "print 'read %d training examples and %d test examples\\n' % (len(train), len(test))\n",
      "print 'all labels: %s\\n' % ','.join(newsgroups)\n",
      "\n",
      "writeFile('data/20ng-named.tr', train)\n",
      "writeFile('data/20ng-named.te', test)\n",
      "\n",
      "print 'files generated:'\n",
      "!wc data/20ng-named.tr data/20ng-named.te\n",
      "print '\\nsome of the examples 9first few words:'\n",
      "!head data/20ng-named.tr | cut -d' ' -f1-10\n",
      "print '\\ntraining vw:'\n",
      "!vw -k -c -b 27 --oaa 20 -d data/20ng-named.tr -f data/20ng-named.model --passes 20 --holdout_after 10001 --named_labels misc.forsale,talk.politics.guns,comp.sys.mac.hardware,talk.politics.misc,soc.religion.christian,comp.graphics,sci.med,talk.religion.misc,comp.windows.x,comp.sys.ibm.pc.hardware,talk.politics.mideast,comp.os.ms-windows.misc,sci.crypt,sci.space,alt.atheism,rec.sport.hockey,rec.sport.baseball,sci.electronics,rec.autos,rec.motorcycles"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "read 11314 training examples and 7532 test examples\n",
        "\n",
        "all labels: misc.forsale,talk.politics.guns,comp.sys.mac.hardware,talk.politics.misc,soc.religion.christian,comp.graphics,sci.med,talk.religion.misc,comp.windows.x,comp.sys.ibm.pc.hardware,talk.politics.mideast,comp.os.ms-windows.misc,sci.crypt,sci.space,alt.atheism,rec.sport.hockey,rec.sport.baseball,sci.electronics,rec.autos,rec.motorcycles\n",
        "\n",
        "files generated:\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "   11314  4248707 20023606 data/20ng-named.tr\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "    7532  2731355 12938462 data/20ng-named.te\r\n",
        "   18846  6980062 32962068 total\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "some of the examples 9first few words:\n",
        "sci.med |S Re ; Homeopathy ; a respectable medical tradition\r\n",
        "sci.med |w In article < 19439 @ pitt . UUCP\r\n",
        "comp.graphics |S Re ; Crimson ( Was ; Kubota Announcement\r\n",
        "comp.sys.mac.hardware |S Re ; Buying a high speed v .\r\n",
        "alt.atheism |S Re ; Slavery ( was Re ; Why\r\n",
        "sci.space |S Re ; HLV for Fred ( was Re\r\n",
        "rec.autos |S Re ; SUPER MEGA AUTOMOBILE SIGHTING ( s\r\n",
        "talk.politics.mideast |S Zionism - racism |w From ; Center for\r\n",
        "talk.politics.mideast |S Freedom In U . S . A .\r\n",
        "alt.atheism |S Re ; Death Penalty / Gulf War |w\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "training vw:\n",
        "parsed 20 named labels\r\n",
        "final_regressor = data/20ng-named.model\r\n",
        "Num weight bits = 27\r\n",
        "learning rate = 0.5\r\n",
        "initial_t = 0\r\n",
        "power_t = 0.5\r\n",
        "decay_learning_rate = 1\r\n",
        "creating cache_file = data/20ng-named.tr.cache\r\n",
        "Reading datafile = data/20ng-named.tr\r\n",
        "num sources = 1\r\n",
        "average  since         example        example  current  current  current\r\n",
        "loss     last          counter         weight    label  predict features\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "1.000000 1.000000            1            1.0  sci.med misc.forsale      485\r\n",
        "0.500000 0.000000            2            2.0  sci.med  sci.med      189\r\n",
        "0.750000 1.000000            4            4.0 comp.sys.mac.hardware comp.graphics      397\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.875000 1.000000            8            8.0 talk.politics.mideast sci.space      556\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.875000 0.875000           16           16.0 comp.sys.mac.hardware rec.autos       65\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.906250 0.937500           32           32.0 rec.autos soc.religion.christian      360\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.859375 0.812500           64           64.0 talk.politics.mideast talk.politics.mideast     1854\r\n",
        "0.875000 0.890625          128          128.0 comp.sys.ibm.pc.hardware talk.politics.guns      183\r\n",
        "0.828125 0.781250          256          256.0 sci.crypt talk.politics.misc      108\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.748047 0.667969          512          512.0 misc.forsale misc.forsale       52\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.625000 0.501953         1024         1024.0 comp.graphics comp.graphics       75\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.489746 0.354492         2048         2048.0 talk.politics.misc talk.religion.misc      357\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.359131 0.228516         4096         4096.0 sci.crypt sci.crypt     1373\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.255615 0.152100         8192         8192.0  sci.med  sci.med      378\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.117960 0.117960        16384        16384.0 sci.space sci.space       93 h\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.104515 0.097793        32768        32768.0 soc.religion.christian soc.religion.christian      725 h\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.097793 0.091071        65536        65536.0 soc.religion.christian soc.religion.christian      203 h\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r\n",
        "finished run\r\n",
        "number of examples per pass = 10000\r\n",
        "passes used = 8\r\n",
        "weighted example sum = 80000.000000\r\n",
        "weighted label sum = 0.000000\r\n",
        "average loss = 0.089041 h\r\n",
        "total feature number = 29528008\r\n",
        "in namedlabels delete\r\n"
       ]
      }
     ],
     "prompt_number": 29
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "As before, we might want to get (raw) predictions out:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!vw -t -i data/20ng-named.model -d data/20ng-named.te -p data/20ng-named.te.pred -r data/20ng-named.te.raw --quiet\n",
      "!head data/20ng-named.te.pred data/20ng-named.te.raw"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "parsed 20 named labels\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "in namedlabels delete\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "==> data/20ng-named.te.pred <==\r\n",
        "misc.forsale\r\n",
        "misc.forsale\r\n",
        "misc.forsale\r\n",
        "misc.forsale\r\n",
        "misc.forsale\r\n",
        "misc.forsale\r\n",
        "misc.forsale\r\n",
        "misc.forsale\r\n",
        "misc.forsale\r\n",
        "misc.forsale\r\n",
        "\r\n",
        "==> data/20ng-named.te.raw <==\r\n",
        "1:0.165563 2:-0.545487 3:-0.687337 4:-0.785096 5:-0.770141 6:-0.853439 7:-0.67065 8:-0.680333 9:-0.43248 10:-0.496228 11:-0.786617 12:-0.577077 13:-0.663512 14:-0.662412 15:-0.842962 16:-0.649093 17:-0.576161 18:-0.659256 19:-0.416848 20:-0.631203\r\n",
        "1:1 2:-1 3:-1 4:-1 5:-1 6:-1 7:-1 8:-1 9:-1 10:-1 11:-1 12:-1 13:-1 14:-1 15:-1 16:-1 17:-1 18:-1 19:-1 20:-1\r\n",
        "1:1 2:-1 3:-1 4:-1 5:-1 6:-1 7:-1 8:-1 9:-1 10:-0.954749 11:-1 12:-1 13:-1 14:-1 15:-1 16:-1 17:-1 18:-1 19:-1 20:-1\r\n",
        "1:0.852943 2:-1 3:-1 4:-1 5:-1 6:-1 7:-1 8:-1 9:-1 10:-1 11:-1 12:-1 13:-0.822948 14:-1 15:-1 16:-1 17:-1 18:-1 19:-0.725594 20:-0.957785\r\n",
        "1:0.0313573 2:-1 3:-1 4:-1 5:-1 6:-0.0448983 7:-0.999964 8:-1 9:-1 10:-1 11:-1 12:-1 13:-1 14:-0.836448 15:-1 16:-1 17:-0.93454 18:-1 19:-1 20:-0.915365\r\n",
        "1:1 2:-1 3:-0.423715 4:-0.835319 5:-0.797933 6:-1 7:-0.947166 8:-1 9:-1 10:-1 11:-0.991583 12:-1 13:-1 14:-1 15:-1 16:-1 17:-1 18:-1 19:-0.864288 20:-1\r\n",
        "1:0.0698868 2:-0.806564 3:-0.801636 4:-1 5:-1 6:-1 7:-1 8:-1 9:-1 10:-1 11:-1 12:-0.618368 13:-1 14:-1 15:-1 16:-1 17:-1 18:-0.985787 19:-1 20:-0.670371\r\n",
        "1:1 2:-1 3:-1 4:-1 5:-1 6:-1 7:-1 8:-1 9:-1 10:-1 11:-1 12:-1 13:-1 14:-1 15:-1 16:-1 17:-1 18:-1 19:-1 20:-1\r\n",
        "1:-0.043292 2:-1 3:-0.826312 4:-0.601213 5:-1 6:-0.535975 7:-0.914093 8:-1 9:-0.885368 10:-1 11:-0.959658 12:-1 13:-1 14:-1 15:-1 16:-0.856573 17:-1 18:-0.552814 19:-1 20:-1\r\n",
        "1:1 2:-1 3:-1 4:-0.930893 5:-1 6:-1 7:-1 8:-1 9:-1 10:-1 11:-1 12:-1 13:-1 14:-1 15:-1 16:-1 17:-1 18:-1 19:-1 20:-1\r\n"
       ]
      }
     ],
     "prompt_number": 30
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Here, you can see that the predictions shows the name of the class. The raw predictions, however, uses the internal numbering. The question then is \"what labels do the different numbers correspond to?\" The answer is that it's just the order you used in the \"`--named_labels`\" argument. In that argument, the first item was `misc.forsale` so that's what `1:...` means here."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "\n",
      "\n",
      "# <a id=\"scaling\"></a> Scaling Up to More Classes\n",
      "\n",
      "In the previous example, we had only 20 classes. For lots of problems, we have more. The problem we'll consider now is the Quiz Bowl question answering task. In this problem, we get a long-form question and have to provide an answer. In the full version of the problem, the goal is to answer the question as *early* as possible (i.e., before the entire question is read). For simplicity here, we'll focus on the simpler problem of just predicting the answer at the end of the question. Our [QANTA system](), which [recently bested Ken Jennings](), get an error rate of about 20% at the end of the question on this task (though trained on more data and also with extra Wikipedia resources). [Mohit Iyyer]() has made [the non-proprietary question/answer pairs available for download]().\n",
      "\n",
      "As usual, we begin by grabbing the data (this is a 31mb download):"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!rm -rf data/question-* data/quizbowl*\n",
      "!curl -o data/question_data.tar.gz http://cs.umd.edu/~miyyer/data/question_data.tar.gz\n",
      "!tar zxC data -f data/question_data.tar.gz\n",
      "!echo \"\"\n",
      "!echo \"counting the number of questions:\"\n",
      "!wc -l data/questions/questions.csv\n",
      "!echo \"\"\n",
      "!echo \"looking at the first question:\"\n",
      "!echo \"\"\n",
      "!head -n2 data/questions/questions.csv"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\r\n",
        "                                 Dload  Upload   Total   Spent    Left  Speed\r\n",
        "\r",
        "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "  8 31.2M    8 2828k    0     0  3220k      0  0:00:09 --:--:--  0:00:09 3217k"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        " 16 31.2M   16 5182k    0     0  2758k      0  0:00:11  0:00:01  0:00:10 2758k"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        " 26 31.2M   26 8511k    0     0  2957k      0  0:00:10  0:00:02  0:00:08 2956k"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        " 38 31.2M   38 12.0M    0     0  3176k      0  0:00:10  0:00:03  0:00:07 3176k"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        " 51 31.2M   51 16.0M    0     0  3371k      0  0:00:09  0:00:04  0:00:05 3371k"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        " 64 31.2M   64 19.9M    0     0  3478k      0  0:00:09  0:00:05  0:00:04 3524k"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        " 73 31.2M   73 23.0M    0     0  3436k      0  0:00:09  0:00:06  0:00:03 3690k"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        " 86 31.2M   86 27.0M    0     0  3518k      0  0:00:09  0:00:07  0:00:02 3842k"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        " 94 31.2M   94 29.4M    0     0  3392k      0  0:00:09  0:00:08  0:00:01 3560k"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "100 31.2M  100 31.2M    0     0  3378k      0  0:00:09  0:00:09 --:--:-- 3387k\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "counting the number of questions:\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "20408 data/questions/questions.csv\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "looking at the first question:\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Question ID,Fold,Category,Answer,Text\r",
        "\r\n",
        "210044,dev,Literature,I Sing the Body Electric (poem),\"This poem describes a sort of person who, \"\"whatever the survey, whatever the sea and sail\"\" \"\"strikes soundings at last only here.\"\" ||| An earlier section of this poem distinguishes love \"\"by allowance\"\" from love  \"\"with personal love,\"\" saying of \"\"a common farmer -- the father of five sons\"\" that \"\"you would wish to sit by him in the boat, that you and he might touch each other.\"\" ||| The speaker of this poem wishes to \"\"swim with the swimmers, wrestle with the wrestlers, march in line with the firemen, pause, listen and count.\"\" ||| Later, it describes the auction of the male and female forms, then launches into an exhaustive anatomical catalogue, concluding that these are \"\"parts and poems\"\" of the soul, and, indeed \"\"these are the Soul!\"\" ||| This poem's speaker states that \"\"the armies of those I love engirth me, and I engirth them.\"\" ||| For 10 points, name this celebration of the physical human being, a poem by Walt Whitman.\"\r",
        "\r\n"
       ]
      }
     ],
     "prompt_number": 31
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "(In this format, \"`|||`\" means \"sentence boundary\".)\n",
      "\n",
      "And now we have to read it in. In this case it's particularly easy because it's generated with Python's csvwriter. The data is already split into train/dev/test for us too:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import csv\n",
      "import sys\n",
      "\n",
      "def readQuizBowlData(filename):\n",
      "    train,dev,test = [],[],[]\n",
      "    data = csv.reader( open(filename, 'r').readlines() )\n",
      "    header = data.next()\n",
      "    if header != ['Question ID', 'Fold', 'Category', 'Answer', 'Text']:\n",
      "        raise Exception('data improperly formatted')\n",
      "    for item in iter(data):\n",
      "        y = item[3]        \n",
      "        x = sanify(' '.join(tokenize(item[4].replace('|||',''))))\n",
      "        if   item[1] == 'train': train.append( (x,y) )\n",
      "        elif item[1] == 'dev'  :   dev.append( (x,y) )\n",
      "        elif item[1] == 'test' :  test.append( (x,y) )\n",
      "    return train,dev,test\n",
      "\n",
      "def makeLabelIDs(train, outputFile):\n",
      "    labelIds = { label: k+1 for k,label in enumerate(set([y for x,y in train])) }\n",
      "    labelIds['***UNKNOWN***'] = len(labelIds)+1\n",
      "    with open(outputFile, 'w') as h:\n",
      "        for label,k in labelIds.iteritems():\n",
      "            print >>h, '%d\\t%s' % (k,label)\n",
      "    return labelIds\n",
      "\n",
      "def writeVWFile(filename, data, labelIds):\n",
      "    unknownId = labelIds['***UNKNOWN***']\n",
      "    with open(filename,'w') as h:\n",
      "        for x,y in data:\n",
      "            print >>h, '%d |q %s' % (labelIds.get(y, unknownId), x)\n",
      "            \n",
      "train,dev,test = readQuizBowlData('data/questions/questions.csv')\n",
      "traindev = train + dev\n",
      "random.seed(9876)\n",
      "random.shuffle(traindev)\n",
      "labelIds = makeLabelIDs(train, 'data/quizbowl.labels')\n",
      "writeVWFile('data/quizbowl.trde', traindev, labelIds)\n",
      "writeVWFile('data/quizbowl.te',   test    , labelIds)\n",
      "print 'maximum label id = %d' % (len(labelIds)+1)\n",
      "!wc data/quizbowl.t[re]*"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "maximum label id = 2322\n",
        "    2601   325113  1707100 data/quizbowl.te\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "   17806  2387362 12553158 data/quizbowl.trde\r\n",
        "   20407  2712475 14260258 total\r\n"
       ]
      }
     ],
     "prompt_number": 32
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "So we have 2322 labels and 17805 train/dev examples. This is obviously going to be a pretty hard problem without auxiliary information. We can still make a go of it!"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!vw -k -c -b 27 -d data/quizbowl.trde --oaa 2322 --passes 20 -f data/quizbowl.model"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "final_regressor = data/quizbowl.model\r\n",
        "Num weight bits = 27\r\n",
        "learning rate = 0.5\r\n",
        "initial_t = 0\r\n",
        "power_t = 0.5\r\n",
        "decay_learning_rate = 1\r\n",
        "creating cache_file = data/quizbowl.trde.cache\r\n",
        "Reading datafile = data/quizbowl.trde\r\n",
        "num sources = 1\r\n",
        "average  since         example        example  current  current  current\r\n",
        "loss     last          counter         weight    label  predict features\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "1.000000 1.000000            1            1.0     1422        1      149\r\n",
        "1.000000 1.000000            2            2.0     1315     1422      174\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "1.000000 1.000000            4            4.0      562     1888      108\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "1.000000 1.000000            8            8.0     1486     1911      110\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "1.000000 1.000000           16           16.0     2010      618      144\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "1.000000 1.000000           32           32.0     2200      410      122\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "1.000000 1.000000           64           64.0     1852      401       65\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "1.000000 1.000000          128          128.0     1388      723      154\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "1.000000 1.000000          256          256.0     1486      710      138\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.994141 0.988281          512          512.0     2229     1251      129\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.987305 0.980469         1024         1024.0      109     1105      121\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.977051 0.966797         2048         2048.0     2011     1572      178\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.946533 0.916016         4096         4096.0      182     1815       82\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.876709 0.806885         8192         8192.0      170     2041      161\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.731721 0.731721        16384        16384.0     2179     2179      146 h\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.533113 0.334615        32768        32768.0     1375     1375      143 h\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.403764 0.274451        65536        65536.0     1489     1489      183 h\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r\n",
        "finished run\r\n",
        "number of examples per pass = 16026\r\n",
        "passes used = 7\r\n",
        "weighted example sum = 112182.000000\r\n",
        "weighted label sum = 0.000000\r\n",
        "average loss = 0.273596 h\r\n",
        "total feature number = 14944118\r\n"
       ]
      }
     ],
     "prompt_number": 33
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "That's 27% holdout error, which, all told, is not that bad. Of course the real question is how well we do on test:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!vw -d data/quizbowl.te -t -i data/quizbowl.model"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "only testing\r\n",
        "Num weight bits = 27\r\n",
        "learning rate = 0.5\r\n",
        "initial_t = 0\r\n",
        "power_t = 0.5\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "using no cache\r\n",
        "Reading datafile = data/quizbowl.te\r\n",
        "num sources = 1\r\n",
        "average  since         example        example  current  current  current\r\n",
        "loss     last          counter         weight    label  predict features\r\n",
        "0.000000 0.000000            1            1.0      798      798      136\r\n",
        "0.000000 0.000000            2            2.0     1031     1031      148\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.250000 0.500000            4            4.0      904        1      162\r\n",
        "0.250000 0.250000            8            8.0      890      890      121\r\n",
        "0.187500 0.125000           16           16.0      142     1894      133\r\n",
        "0.156250 0.125000           32           32.0     1887     1887      113\r\n",
        "0.187500 0.218750           64           64.0      807      951      125\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.171875 0.156250          128          128.0     1511     1511      135\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.187500 0.203125          256          256.0     2321     2321      159\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.177734 0.167969          512          512.0     2229     2264      135\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.188477 0.199219         1024         1024.0      439      439      131\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.188477 0.188477         2048         2048.0      896      896      112\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r\n",
        "finished run\r\n",
        "number of examples per pass = 2601\r\n",
        "passes used = 1\r\n",
        "weighted example sum = 2601.000000\r\n",
        "weighted label sum = 0.000000\r\n",
        "average loss = 0.200308\r\n",
        "total feature number = 322512\r\n"
       ]
      }
     ],
     "prompt_number": 34
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Wow, 20% test loss. This is actually quite impressive for basically doing no work. One legitimate question is what is the frequency of the most frequent class:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from collections import Counter\n",
      "labelFreq = Counter([y for x,y in train])\n",
      "print labelFreq.most_common(10)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[('Robert Frost', 20), ('Japan', 19), ('Australia', 16), ('Mexico', 16), ('Poland', 16), ('Robert Schumann', 15), ('Henry Wadsworth Longfellow', 14), ('Canada', 14), ('Alcohol', 14), ('China', 14)]\n"
       ]
      }
     ],
     "prompt_number": 35
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "So out of 8800 training examples, the most frequent one only occurs twenty times, which is not very much. Of course the \"unknown\" label could dominate in test. It's unlikely we would predict that label since we never saw it at training time, but it's possible. Let's make sure:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!cat data/quizbowl.te | cut -d' ' -f1 | sort | uniq -c | sort -g | tail"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "      6 2064\r\n",
        "      6 2145\r\n",
        "      6 334\r\n",
        "      6 459\r\n",
        "      6 528\r\n",
        "      6 788\r\n",
        "      6 927\r\n",
        "      7 1144\r\n",
        "      8 1841\r\n",
        "     75 2321\r\n"
       ]
      }
     ],
     "prompt_number": 36
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "So the most frequent label *is* indeed the \"never seen this answer before\" label, but it still only appears in 75/2600 examples, which is only about 2.8%. Definitely not a winning strategy!\n",
      "\n",
      "# <a id=\"alter\"></a> Alternatives to One Against All\n",
      "\n",
      "You may have noticed that training on the quizbowl data, especially for a relatively small data set, was kind of slow. This is because OAA time complexity scales like O(K), where K is the number of classes. This is fine for something like 20 Newsgroups, but bad for problems with lots of classes.\n",
      "\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!time vw -k -c -b 29 -d data/quizbowl.trde --log_multi 2322 --passes 10 --early_terminate 999 -f data/quizbowl.model2\n",
      "!vw -d data/quizbowl.te -t -i data/quizbowl.model2 2>&1 | grep '^average loss'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "final_regressor = data/quizbowl.model2\r\n",
        "Num weight bits = 29\r\n",
        "learning rate = 0.5\r\n",
        "initial_t = 0\r\n",
        "power_t = 0.5\r\n",
        "decay_learning_rate = 1\r\n",
        "creating cache_file = data/quizbowl.trde.cache\r\n",
        "Reading datafile = data/quizbowl.trde\r\n",
        "num sources = 1\r\n",
        "average  since         example        example  current  current  current\r\n",
        "loss     last          counter         weight    label  predict features\r\n",
        "1.000000 1.000000            1            1.0     1422        1      149\r\n",
        "1.000000 1.000000            2            2.0     1315     1422      174\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "1.000000 1.000000            4            4.0      562     1888      108\r\n",
        "1.000000 1.000000            8            8.0     1486     1911      110\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "1.000000 1.000000           16           16.0     2010      618      144\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "1.000000 1.000000           32           32.0     2200       62      122\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "1.000000 1.000000           64           64.0     1852     1317       65\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "1.000000 1.000000          128          128.0     1388     2193      154\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.992188 0.984375          256          256.0     1486     1539      138\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.994141 0.996094          512          512.0     2229      473      129\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.987305 0.980469         1024         1024.0      109      313      121\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.979004 0.970703         2048         2048.0     2011     1749      178\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.960693 0.942383         4096         4096.0      182      955       82\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.913452 0.866211         8192         8192.0      170      170      161\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.807587 0.807587        16384        16384.0     2179     2179      146 h\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.678208 0.548901        32768        32768.0     1375     1375      143 h\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.585383 0.492582        65536        65536.0     1489     1489      183 h\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.529400 0.473417       131072       131072.0      941      941      138 h\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r\n",
        "finished run\r\n",
        "number of examples per pass = 16026\r\n",
        "passes used = 10"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r\n",
        "weighted example sum = 160260.000000\r\n",
        "weighted label sum = 0.000000\r\n",
        "average loss = 0.463483 h\r\n",
        "total feature number = 21348740\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "95.98user 17.69system 1:52.57elapsed 100%CPU (0avgtext+0avgdata 2504272maxresident)k\r\n",
        "0inputs+632640outputs (0major+355831minor)pagefaults 0swaps\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "average loss = 0.407536\r\n"
       ]
      }
     ],
     "prompt_number": 37
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "So that took (on my laptop) about 2 minutes of wallclock time and gets an error rate of 40%, which is significantly worse than OAA. If we give OAA approximately the same amount of time, this is what happens:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!time vw -k -c -b 27 -d data/quizbowl.trde --oaa 2322 --passes 2 -f data/quizbowl.model\n",
      "!vw -d data/quizbowl.te -t -i data/quizbowl.model2 2>&1 | grep '^average loss'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "final_regressor = data/quizbowl.model\r\n",
        "Num weight bits = 27\r\n",
        "learning rate = 0.5\r\n",
        "initial_t = 0\r\n",
        "power_t = 0.5\r\n",
        "decay_learning_rate = 1\r\n",
        "creating cache_file = data/quizbowl.trde.cache\r\n",
        "Reading datafile = data/quizbowl.trde\r\n",
        "num sources = 1\r\n",
        "average  since         example        example  current  current  current\r\n",
        "loss     last          counter         weight    label  predict features\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "1.000000 1.000000            1            1.0     1422        1      149\r\n",
        "1.000000 1.000000            2            2.0     1315     1422      174\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "1.000000 1.000000            4            4.0      562     1888      108\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "1.000000 1.000000            8            8.0     1486     1911      110\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "1.000000 1.000000           16           16.0     2010      618      144\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "1.000000 1.000000           32           32.0     2200      410      122\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "1.000000 1.000000           64           64.0     1852      401       65\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "1.000000 1.000000          128          128.0     1388      723      154\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "1.000000 1.000000          256          256.0     1486      710      138\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.994141 0.988281          512          512.0     2229     1251      129\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.987305 0.980469         1024         1024.0      109     1105      121\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.977051 0.966797         2048         2048.0     2011     1572      178\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.946533 0.916016         4096         4096.0      182     1815       82\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.876709 0.806885         8192         8192.0      170     2041      161\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.731721 0.731721        16384        16384.0     2179     2179      146 h\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r\n",
        "finished run\r\n",
        "number of examples per pass = 16026\r\n",
        "passes used = 2\r\n",
        "weighted example sum = 32052.000000\r\n",
        "weighted label sum = 0.000000\r\n",
        "average loss = 0.335955 h\r\n",
        "total feature number = 4269748\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "108.09user 1.74system 1:49.02elapsed 100%CPU (0avgtext+0avgdata 1754464maxresident)k\r\n",
        "16inputs+669896outputs (0major+112518minor)pagefaults 0swaps\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "average loss = 0.407536\r\n"
       ]
      }
     ],
     "prompt_number": 38
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "So that took about the same amount of time and got a loss of 40%.\n",
      "\n",
      "In this case, it appears there is a flat out tie :(. However, as the number of classes grows, eventually OAA becomes untenable and you really cannot afford the O(K) computation. More details are in the [LOMTree paper](http://arxiv.org/abs/1406.1822)."
     ]
    }
   ],
   "metadata": {}
  }
 ]
}